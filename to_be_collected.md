## 用户模型是什么？

### 用户ID是如何设计的？

UUID

是一个128比特的数值，这个数值可以通过一定的算法计算出来。

为了提高效率，常用的UUID可缩短至16位。





## 密码

### 密码是明文还是暗文？

### 密码如何加密的？

### 密码如何传输的？





邮箱/手机发送验证码用的是什么服务？



thinkphp

国内的框架，好上手，轻量级，开发速度快





表单提交

post 表单

get 通过URL，

#### sha1 和 sha256是什么？

**安全散列算法**（英语：Secure Hash Algorithm，缩写为SHA）是一个[密码散列函数](https://zh.wikipedia.org/wiki/密碼雜湊函數)家族，是[FIPS](https://zh.wikipedia.org/wiki/联邦资料处理标准)所认证的安全[散列算法](https://zh.wikipedia.org/wiki/雜湊函數)。能计算出一个数字消息所对应到的，长度固定的字符串（又称消息摘要）的算法。且若输入的消息不同，它们对应到不同字符串的几率很高。

**[SHA-1](https://zh.wikipedia.org/wiki/SHA-1)**：1995年发布，SHA-1在许多安全协议中广为使用，包括[TLS](https://zh.wikipedia.org/wiki/TLS)、[GnuPG](https://zh.wikipedia.org/wiki/GnuPG)、[SSH](https://zh.wikipedia.org/wiki/Secure_Shell)、[S/MIME](https://zh.wikipedia.org/wiki/S/MIME)和[IPsec](https://zh.wikipedia.org/wiki/IPsec)，是[MD5](https://zh.wikipedia.org/wiki/MD5)的后继者。但SHA-1的安全性在2010年以后已经不被大多数的加密场景所接受。2017年荷兰密码学研究小组CWI和Google正式宣布攻破了SHA-1[[1\]](https://zh.wikipedia.org/wiki/SHA家族#cite_note-1)。

**[SHA-2](https://zh.wikipedia.org/wiki/SHA-2)**：2001年发布，包括SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224、SHA-512/256。SHA-2目前没有出现明显的弱点。虽然至今尚未出现对SHA-2有效的攻击，但它的算法跟SHA-1基本上仍然相似。

**[SHA-3](https://zh.wikipedia.org/wiki/SHA-3)**：2015年正式发布，由于对MD5出现成功的破解，以及对SHA-0和SHA-1出现理论上破解的方法，[NIST](https://zh.wikipedia.org/wiki/國家標準暨技術研究院)感觉需要一个与之前算法不同的，可替换的加密散列算法，也就是现在的SHA-3。

MD5输出128bit、SHA1输出160bit、SHA256输出256bit
`SHA-1`是160位的哈希值，而`SHA-2`是组合值，有不同的位数，其中最受欢迎的是256位。



# 常见的用户密码加密方式以及破解方法

https://cloud.tencent.com/developer/article/1186925

要完全防止信息泄露是非常困难的事情，除了防止黑客外，还要防止内部人员泄密。但如果采用合适的算法去加密用户密码，即使信息泄露出去，黑客也无法还原出原始的密码（或者还原的代价非常大）。也就是说我们可以将工作重点从防止泄露转换到防止黑客还原出数据。

- 本文首发于InfoQ垂直号「聊聊架构」。

作为互联网公司的信息安全从业人员经常要处理撞库扫号事件，产生撞库扫号的根本原因是一些企业发生了信息泄露事件，且这些泄露数据未加密或者加密方式比较弱，导致黑客可以还原出原始的用户密码。

目前已经曝光的信息泄露事件至少上百起，其中包括多家一线互联网公司，泄露总数据超过10亿条。本文作者就职于携程技术中心信息安全部，文中他将分享用户密码的加密方式以及主要的破解方法。

**用户密码加密**

用户密码保存到数据库时，常见的加密方式有哪些，我们该采用什么方式来保护用户的密码呢？以下几种方式是常见的密码保存方式：

1. 直接明文保存，比如用户设置的密码是“123456”，直接将“123456”保存在数据库中，这种是最简单的保存方式，也是最不安全的方式。但实际上不少互联网公司，都可能采取的是这种方式。
2. 使用对称加密算法来保存，比如3DES、AES等算法，使用这种方式加密是可以通过解密来还原出原始密码的，当然前提条件是需要获取到密钥。不过既然大量的用户信息已经泄露了，密钥很可能也会泄露，当然可以将一般数据和密钥分开存储、分开管理，但要完全保护好密钥也是一件非常复杂的事情，所以这种方式并不是很好的方式。

![img](https://ask.qcloudimg.com/http-save/yehe-2802732/u8hwpc2lvz.png?imageView2/2/w/1620)

1. 使用MD5、SHA1等单向HASH算法保护密码，使用这些算法后，无法通过计算还原出原始密码，而且实现比较简单，因此很多互联网公司都采用这种方式保存用户密码，曾经这种方式也是比较安全的方式，但随着彩虹表技术的兴起，可以建立彩虹表进行查表破解，目前这种方式已经很不安全了。

![img](https://ask.qcloudimg.com/http-save/yehe-2802732/f4hmqvd3ju.png?imageView2/2/w/1620)

1. 特殊的单向HASH算法，由于单向HASH算法在保护密码方面不再安全，于是有些公司在单向HASH算法基础上进行了加盐、多次HASH等扩展，这些方式可以在一定程度上增加破解难度，对于加了“固定盐”的HASH算法，需要保护“盐”不能泄露，这就会遇到“保护对称密钥”一样的问题，一旦“盐”泄露，根据“盐”重新建立彩虹表可以进行破解，对于多次HASH，也只是增加了破解的时间，并没有本质上的提升。

![img](https://ask.qcloudimg.com/http-save/yehe-2802732/xw4h9e40kd.png?imageView2/2/w/1620)

1. PBKDF2算法，该算法原理大致相当于在HASH算法基础上增加随机盐，并进行多次HASH运算，随机盐使得彩虹表的建表难度大幅增加，而多次HASH也使得建表和破解的难度都大幅增加。使用PBKDF2算法时，HASH算法一般选用sha1或者sha256，随机盐的长度一般不能少于8字节，HASH次数至少也要1000次，这样安全性才足够高。 一次密码验证过程进行1000次HASH运算，对服务器来说可能只需要1ms，但对于破解者来说计算成本增加了1000倍，而至少8字节随机盐，更是把建表难度提升了N个数量级，使得大批量的破解密码几乎不可行，该算法也是美国国家标准与技术研究院推荐使用的算法。

![img](https://ask.qcloudimg.com/http-save/yehe-2802732/hg6x2mnxfx.png?imageView2/2/w/1620)

1. bcrypt、scrypt等算法，这两种算法也可以有效抵御彩虹表，使用这两种算法时也需要指定相应的参数，使破解难度增加。

下表对比了各个算法的特性：

| 算法     | 特点           | 有效破解方式 | 破解难度 | 其它               |
| :------- | :------------- | :----------- | :------- | :----------------- |
| 明文保存 | 实现简单       | 无需破解     | 简单     |                    |
| 对称加密 | 可以解密出明文 | 获取密钥     | 中       | 需要确保密钥不泄露 |
| 单向HASH | 不可解密       | 碰撞、彩虹表 | 中       |                    |
| 特殊HASH | 不可解密       | 碰撞、彩虹表 | 中       | 需要确保“盐”不泄露 |
| Pbkdf2   | 不可解密       | 无           | 难       | 需要设定合理的参数 |

**用户密码破解**

用户密码破解需要针对具体的加密方式来实施，如果使用对称加密，并且算法足够安全（比如AES），必须获取到密钥才能解密，没有其它可行的破解方式。

如果采用HASH算法（包括特殊HASH），一般使用彩虹表的方式来破解，彩虹表的原理是什么呢？我们先来了解下如何进行HASH碰撞。单向HASH算法由于不能进行解密运算，只能通过建表、查表的方式进行碰撞，即将常用的密码及其对应的HASH值全计算出来并存储，当获取到HASH值是，直接查表获取原始密码，假设用MD5算法来保护6位数字密码，可以建如下表：

| 原始密码 | MD5值                            |
| :------- | :------------------------------- |
| 0        | 670B14728AD9902AECBA32E22FA4F6BD |
| 1        | 04FC711301F3C784D66955D98D399AFB |
| …        | …                                |
| 999999   | 52C69E3A57331081823331C4E69D3F2E |

全表共100W条记录，因为数据量不大，这种情况建表、查表都非常容易。但是当密码并不是6位纯数字密码，而是数字、大小写字母结合的10位密码时，建立一个这样的表需要（26+26+10）^ 10 ≈ 83亿亿（条记录），存储在硬盘上至少要占用2000W TB的空间，这么大的存储空间，成本太大，几乎不可行。

有什么办法可以减少存储空间？一种方法是“预计算哈希链”，“预计算哈希链”可以大幅减少HASH表的存储空间，但相应的增加了查表时的计算量，其原理大致如下：

建表过程：

![img](https://ask.qcloudimg.com/http-save/yehe-2802732/ko4eews0ha.png?imageView2/2/w/1620)

先对原始数据“000000”进行一次HASH运算得到“670B1E”，再对HASH值进行一次R运算，R是一个定制的算法可以将HASH值映射到明文空间上（这里我们的明文空间是000000~999999），R运算后得到“283651”，再对“283651”进行hash运算得到“1A99CD”，然后在进行R运算得到“819287”，如此重复多次，得到一条哈希链。然后再选用其它原始数据建立多条哈希链。最终仅将链头和链尾保存下来，中间节点全都去掉。

查表过程：假设拿到了一条HASH值“670B1E”，首先进行一次R运算，得到了“283651”，查询所有链尾是否有命中，如果没有，则再进行一次HASH、一次R，得到了“819287”，再次所有链尾，可以得到看出已经命中。

这样我们就可以基本确认“670B1E”对应的明文就在这条链上，然后我们把这条链的生成过程进行重新计算，计算过程中可以发现“000000”的HASH值就是“670B1E”，这样就完成了整个查表过程。这种表就是“预计算哈希链”。这种方式存在一个问题，多条链之间可能存在大量的重复数据，如下图所示：

![img](https://ask.qcloudimg.com/http-save/yehe-2802732/94nl3p97in.png?imageView2/2/w/1620)

为了解决这个问题，我们将R算法进行扩展，一条链上的多次R运算采用不同的算法，如下图：

![img](https://ask.qcloudimg.com/http-save/yehe-2802732/x7jum86w8a.png?imageView2/2/w/1620)

一条链上的每个R算法都不一样，就像彩虹的每层颜色一样，因此取名的为彩虹表。

当然彩虹表除了可以用户破解HASH算法外，理论上还可以用于破解对称加密算法，比如DES算法，由于DES算法密钥比较短，建立彩虹表破解是完全可行的；但对于AES算法，由于密钥比较长，建表几乎不可行（需要耗时N亿年）

**小结**

采用PBKDF2、bcrypt、scrypt等算法可以有效抵御彩虹表攻击，即使数据泄露，最关键的“用户密码”仍然可以得到有效的保护，黑客无法大批量破解用户密码，从而切断撞库扫号的根源。当然，对于已经泄露的密码，还是需要用户尽快修改密码，不要再使用已泄露的密码。 

END





# QPS

术语说明：
QPS = req/sec = 请求数/秒

【QPS计算PV和机器的方式】

QPS统计方式 [一般使用 http_load 进行统计]
QPS = 总请求数 / ( 进程总数 *   请求时间 )
QPS: 单个进程每秒请求服务器的成功次数

单台服务器每天PV计算
公式1：每天总PV = QPS * 3600 * 6
公式2：每天总PV = QPS * 3600 * 8

服务器计算
服务器数量 =   ceil( 每天总PV / 单台服务器每天总PV )

【峰值QPS和机器计算公式】

原理：每天80%的访问集中在20%的时间里，这20%时间叫做峰值时间
公式：( 总PV数 * 80% ) / ( 每天秒数 * 20% ) = 峰值时间每秒请求数(QPS)
机器：峰值时间每秒QPS / 单台机器的QPS   = 需要的机器

问：每天300w PV 的在单台机器上，这台机器需要多少QPS？
答：( 3000000 * 0.8 ) / (86400 * 0.2 ) = 139 (QPS)

问：如果一台机器的QPS是58，需要几台机器来支持？
答：139 / 58 = 3



作者：笑面弥勒
链接：https://www.zhihu.com/question/21556347/answer/83666444
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。





# 分布式系统全局唯一ID简介、特点、5种生成方式

## 什么是分布式系统唯一ID

**在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。**

如在金融、电商、支付、等产品的系统中，数据日渐增长，对数据分库分表后需要有一个唯一ID来标识一条数据或消息，数据库的自增ID显然不能满足需求，此时一个能够生成全局唯一ID的系统是非常必要的。

## 分布式系统唯一ID的特点

1. **全局唯一性**：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。
2.  **趋势递增**：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。
3.  **单调递增**：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。
4.  **信息安全**：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。

同时除了对ID号码自身的要求，业务还对ID号生成系统的可用性要求极高，想象一下，如果ID生成系统瘫痪，这就会带来一场灾难。

**由此总结下一个ID生成系统应该做到如下几点：**

1.  平均延迟和TP999延迟都要尽可能低；
2.  可用性5个9；
3.  高QPS。

![阿里P8架构师谈：分布式系统全局唯一ID简介、特点、5种生成方式](http://p9.pstatp.com/large/pgc-image/154087893553090efb99cc6)

**1.UUID**

UUID(Universally Unique Identifier)的标准型式包含32个16进制数字，以连字号分为五段，形式为8-4-4-4-12的36个字符，示例：550e8400-e29b-41d4-a716-446655440000，到目前为止业界一共有5种方式生成UUID，详情见IETF发布的UUID规范 A Universally Unique IDentifier (UUID) URN Namespace。

**优点：**

-  性能非常高：本地生成，没有网络消耗。

**缺点：**

-  不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。
-  信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。
-  ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用：

**2.数据库生成**

以MySQL举例，利用给字段设置auto_increment_increment和auto_increment_offset来保证ID自增，每次业务使用下列SQL读写MySQL得到ID号。

![阿里P8架构师谈：分布式系统全局唯一ID简介、特点、5种生成方式](http://p99.pstatp.com/large/pgc-image/1540877607739bfb915347d)

这种方案的优缺点如下：

**优点：**

-  非常简单，利用现有数据库系统的功能实现，成本小，有DBA专业维护。
-  ID号单调自增，可以实现一些对ID有特殊要求的业务。

**缺点：**

-  强依赖DB，当DB异常时整个系统不可用，属于致命问题。配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证。主从切换时的不一致可能会导致重复发号。
-  ID发号性能瓶颈限制在单台MySQL的读写性能。

**3.Redis生成ID**

当使用数据库来生成ID性能不够要求的时候，我们可以尝试使用Redis来生成ID。

这主要依赖于Redis是单线程的，所以也可以用生成全局唯一的ID。可以用Redis的原子操作 INCR和INCRBY来实现。

比较适合使用Redis来生成每天从0开始的流水号。比如订单号=日期+当日自增长号。可以每天在Redis中生成一个Key，使用INCR进行累加。

**优点：**

1）不依赖于数据库，灵活方便，且性能优于数据库。

2）数字ID天然排序，对分页或者需要排序的结果很有帮助。

**缺点：**

1）如果系统中没有Redis，还需要引入新的组件，增加系统复杂度。

2）需要编码和配置的工作量比较大。

**4.利用zookeeper生成唯一ID**

zookeeper主要通过其znode数据版本来生成序列号，可以生成32位和64位的数据版本号，客户端可以使用这个版本号来作为唯一的序列号。

很少会使用zookeeper来生成唯一ID。主要是由于需要依赖zookeeper，并且是多步调用API，如果在竞争较大的情况下，需要考虑使用分布式锁。因此，性能在高并发的分布式环境下，也不甚理想。

**5.snowflake（雪花算法）方案**

这种方案大致来说是一种以划分命名空间（UUID也算，由于比较常见，所以单独分析）来生成ID的一种算法，这种方案把64-bit分别划分成多段，分开来标示机器、时间等，比如在snowflake中的64-bit分别表示如下图（图片来自网络）所示：

![阿里P8架构师谈：分布式系统全局唯一ID简介、特点、5种生成方式](http://p3.pstatp.com/large/pgc-image/1540878012660bd7a0524a0)

41-bit的时间可以表示（1L<<41）/(1000L*3600*24*365)=69年的时间，10-bit机器可以分别表示1024台机器。如果我们对IDC划分有需求，还可以将10-bit分5-bit给IDC，分5-bit给工作机器。这样就可以表示32个IDC，每个IDC下可以有32台机器，可以根据自身需求定义。12个自增序列号可以表示2^12个ID，理论上snowflake方案的QPS约为409.6w/s，这种分配方式可以保证在任何一个IDC的任何一台机器在任意毫秒内生成的ID都是不同的。

这种方式的优缺点是：

**优点：**

-  毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。
-  不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。
-  可以根据自身业务特性分配bit位，非常灵活。

**缺点：**

-  强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。

**应用举例Mongdb objectID**

MongoDB官方文档 ObjectID可以算作是和snowflake类似方法，通过“时间+机器码+pid+inc”共12个字节，通过4+3+2+3的方式最终标识成一个24长度的十六进制字符。


# 

## BI是什么？



## BI的用户是谁？



## BI有哪些模块



## 设计BI需要注意什么？



## 市面上知名的BI有哪些？



# SQL

## SQL注释

1. --：表示单行注释
2. /\*…*/：用于多行（块）注释

## 学习资源

* https://sqlzoo.net/
* https://www.nowcoder.com/

```sql
select id,title,'usa' as country from movies --如果country这一列，可以通过这种方式来进行创建
```

``` sql
SELECT ProductName, ROUND(UnitPrice,0) as UnitPrice FROM Products -- ROUND把数值字段舍入为指定的小数位数，后面的0，是0为小数位
```



## 逻辑运算符有:

- NOT 或者 !
- AND 或者 &&
- OR 或者 ||
- XOR（异或）





# SaaS

https://www.sohu.com/a/298369905_505790

http://www.cniteyes.com/archives/35510


# SaaS

https://www.sohu.com/a/298369905_505790

http://www.cniteyes.com/archives/35510

## Experience

1. 在任何 SaaS 公司的早期，产品就是公司本身，没有那么多虚头八脑的东西，公司创始人是谁、融了多少钱都和客户没什么关系，客户就只认产品是否能解决他们的问题，以及代价是否在可接受的范围之内。
2. PM不仅要懂业务逻辑，还要知道客户痛点，更要紧的是，他们需要持续关注客户体验. 
3. 产品评估周期需要持续性进行评估，频率越高越好，要时刻清除产品是否真正解决了客户的问题，否则他们可能随时跑路。
4. 获客策略可以进行一定程度调整，比如将【使用过**竞品的潜在客户】作为一个特定的用户画像，发现了竞品一个或多个无法解决的问题。我们甚至针对性的产出了几篇文章。
5. 



## 1. SaaS 或 to B 的 PM 和传统软件 PM 有何区别？

SaaS 产品的迭代速度和交付体验是远远高于传统软件产品。



## 2. to B 产品经理生存的根本技能或者素养是什么？

产品经理必须在客户试用的前两周之内充当全职客户成功人员，包括而不限于客户的产品培训、需求调试和交付。

以一个业务人员的标准去要求 to B 的产品经理是不过分的，甚至是必要的。甚至可以考虑让产品经理给客户进行培训。





## 3. to B 产品经理一般应该关注哪些指标？我们如何评判 SaaS 产品经理的工作成效？

至少在 SaaS 产品的早期，客户的留存率（retention）、客户的生命周期价值（LTV）甚至公司月度性重复收入（MRR）都是不值得关注的，一方面是因为这些数据前期无法准确计算，一方面我们有更重要的东西需要去看。

### 3.1 首先就是产品的使用率（Overall platform usage）

#### 客户使用产品的频率如何

是否每天使用等等。

#### 客户到底使用了哪些功能

谁，使用了哪些功能。

### 3.2 特定功能的接受度（Feature-specific adoption）

这个东西似乎很少见，原因在于，我们发现，无论我们推出多少功能，客户都基本只使用其中的某 40%，比如有的客户就只使用自动化却从不用客户分层和商机看板.



## 4. SaaS 产品可以预见的趋势是怎样的？

### 4.1 中台机会

当前有很多 SaaS 产品尝试走平台路线，这个太难做了，机会很少。

我们更想做一个中台，甚至我们觉得中台这个词都有点大，我们更多的是想做一个 single-point service（单点服务，或单点解决方案），在大型平台里充当垂直领域的解决方案，比如我们发现企业微信的生态里就有很多新零售行业的标杆客户需要各项能力满足，CRM 便是其中非常典型的一项，所以我们最近在频繁的寻找新零售行业做标准化和定制化的探索。

另外，我们也发现很多教育或者知识付费类的客户*（彩蛋 3），也经常使用小鹅通做活动和课程交付，为此我们针对这样的平台也提供了 API 对接，直接将客户信息导入到微信 CRM 中，做进一步的客户画像和分层营销管理。

这些场景其实都不大，我们充当某个客户「外部中台」的特定服务能力，这是我们对未来 Martech 领域的一个认定趋势：做中台，而不是平台。

### 4.2 社交机会。

钉钉虽然拥有众多的 SaaS 应用生态，但还是没有切到商务沟通场景，而更多的是一个内部沟通工具，这在我们看来是很危险的一个迹象（和微信及企业微信相比）。商务沟通场景主要还是在微信生态中进行，甚至以后还可能在头条系中进行（比如抖音/快手）。我们认为这些社交产品的商务类型沟通是一个非常值得关注的趋势，实际上我们的鲸奇 SCRM 目前就完全基于微信沟通做后续的 CRM 和自动化延展。其中的 S，也就是 Social，也将会逐步拓展到其他社交软件生态中。





to B 产品经理的成长迭代之道

1. 接下来 



# NLU

> 自然语言理解(NLU)跟 [NLP](https://easyai.tech/ai-definition/nlp/) 是什么关系？为什么说它是人工智能领域里一个难点？NLU 的发展史历史和目前最现金的方法是什么？
>
> 本文将解答上面的问题，带你全面了解自然语言理解(NLU)。
>
> 想要了解更多 NLP 相关的内容，请访问 NLP专题 ，免费提供59页的NLP文档下载。
>
>  访问 NLP 专题，下载 59 页免费 PDF

 

## 什么是自然语言理解(NLU)？

大家最常听到的是 NLP，而 自然语言理解（NLU） 则是 NLP 的一部分：

**什么是自然语言？**

自然语言就是大家平时在生活中常用的表达方式，大家平时说的「讲人话」就是这个意思。

> 自然语言：我背有点驼(非自然语言：我的背部呈弯曲状)
>
> 自然语言：宝宝的经纪人睡了宝宝的宝宝

**自然语言理解就是希望机器像人一样，具备正常人的语言理解能力**，由于自然语言在理解上有很多难点(下面详细说明)，所以 NLU 是至今还远不如人类的表现。



下面用一个具体的案例来深度说明一下自然语言理解（NLU）：

对话系统这个事情在2015年开始突然火起来了，主要是因为一个技术的普及：机器学习特别是深度学习带来的语音识别和NLU(自然语言理解)——主要解决的是识别人讲的话。

这个技术的普及让很多团队都掌握了一组关键技能：**意图识别和实体提取**。

这意味着什么？我们来看一个例子。

在生活中，如果想要订机票，人们会有很多种自然的表达：

> “订机票”；
>
> “有去上海的航班么？”；
>
> “看看航班，下周二出发去纽约的”；
>
> “要出差，帮我查下机票”；
>
> 等等等等

可以说“自然的表达” 有无穷多的组合（自然语言）都是在代表 “订机票” 这个意图的。而听到这些表达的人，可以准确理解这些表达指的是“订机票”这件事。



而要理解这么多种不同的表达，对机器是个挑战。在过去，机器只能处理“结构化的数据”（比如关键词），也就是说如果要听懂人在讲什么，必须要用户输入精确的指令。

所以，无论你说“我要出差”还是“帮我看看去北京的航班”，只要这些字里面没有包含提前设定好的关键词“订机票”，系统都无法处理。而且，只要出现了关键词，比如“我要退订机票”里也有这三个字，也会被处理成用户想要订机票。



自然语言理解这个技能出现后，可以让机器从各种自然语言的表达中，区分出来，哪些话归属于这个意图；而那些表达不是归于这一类的，而不再依赖那么死板的关键词。比如经过训练后，机器能够识别“帮我推荐一家附近的餐厅”，就不属于“订机票”这个意图的表达。

并且，通过训练，机器还能够在句子当中自动提取出来“上海”，这两个字指的是目的地这个概念（即实体）；“下周二”指的是出发时间。

这样一来，看上去“机器就能听懂人话啦！”。



## 自然语言理解（NLU）的应用

几乎所有跟文字语言和语音相关的应用都会用到 NLU，下面举一些具体的例子。



**机器翻译**

基于规则的翻译效果经常不太好，所以如果想提升翻译的效果，必须建立在对内容的理解之上。

如果是不理解上下文，就会出现下面的笑话：

> I like apple, it’s so fast!
>
> 我喜欢「苹果」，它很快！

 

**机器客服**

如果想实现问答，就要建立在多轮对话的理解基础之上，自然语言理解是必备的能力。

下面的例子对于机器来说就很难理解：

> “有什么可以帮您？”
>
> “你好，我想投诉”
>
> “请问投诉的车牌号是多少？”
>
> “xxxxxx”
>
> “请问是什么问题？”
>
> “我刚上车，那个态度恶劣的哥谭市民就冲我发火”

机器很容易理解为：那个态度恶劣/的/哥谭/市民/就冲我发火

 

**智能音箱**

智能音箱中，NLU 也是重要的一个环节。很多语音交互都是很短的短语，音箱不但需要能否识别用户在说什么话，更要理解用户的意图。

> “我冷了”
>
> 机器：帮您把空调调高1度

用户并没有提到空调，但是机器需要知道用户的意图——空调有点冷，需要把温度调高。

 

## 自然语言理解（NLU）的难点

下面先列举一些机器不容易理解的案例：

1. 校长说衣服上除了校徽别别别的
2. 过几天天天天气不好
3. 看见西门吹雪点上了灯，叶孤城冷笑着说：“我也想吹吹吹雪吹过的灯”，然后就吹灭了灯。
4. 今天多得谢逊出手相救，在这里我想真心感谢“谢谢谢逊大侠出手”
5. 灭霸把美队按在地上一边摩擦一边给他洗脑，被打残的钢铁侠说：灭霸爸爸叭叭叭叭儿的在那叭叭啥呢
6. 姑姑你估估我鼓鼓的口袋里有多少谷和菇！！
7. “你看到王刚了吗”“王刚刚刚刚走”
8. 张杰陪俩女儿跳格子：俏俏我们不要跳跳跳跳过的格子啦



那么对于机器来说，NLU 难点大致可以归为5类：

### 难点1：语言的多样性

自然语言没有什么通用的规律，你总能找到很多例外的情况。

另外，自然语言的组合方式非常灵活，字、词、短语、句子、段落…不同的组合可以表达出很多的含义。例如：

> 我要听大王叫我来巡山
>
> 给我播大王叫我来巡山
>
> 我想听歌大王叫我来巡山
>
> 放首大王叫我来巡山
>
> 给唱一首大王叫我来巡山
>
> 放音乐大王叫我来巡山
>
> 放首歌大王叫我来巡山
>
> 给大爷来首大王叫我来巡山

 

### 难点2：语言的歧义性

如果不联系上下文，缺少环境的约束，语言有很大的歧义性。例如：

> 我要去拉萨

- 需要火车票？
- 需要飞机票？
- 想听音乐？
- 还是想查找景点？

 

### 难点3：语言的鲁棒性

自然语言在输入的过程中，尤其是通过语音识别获得的文本，会存在多字、少字、错字、噪音等问题。例如：

> 大王叫我来新山
>
> 大王叫让我来巡山
>
> 大王叫我巡山

 

### 难点4：语言的知识依赖

语言是对世界的符号化描述，语言天然连接着世界知识，例如：

> 大鸭梨

除了表示水果，还可以表示餐厅名

> 7天

可以表示时间，也可以表示酒店名

> 晚安

有一首歌也叫《晚安》

 

### 难点5：语言的上下文

上下文的概念包括很多种：对话的上下文、设备的上下文、应用的上下文、用户画像…

> U：买张火车票
>
> A：请问你要去哪里？
>
> U：宁夏

 

> U：来首歌听
>
> A：请问你想听什么歌？
>
> U：宁夏

 

## NLU 的实现方式

自然语言理解跟整个人工智能的发展历史类似，一共经历了3次迭代：

1. 基于规则的方法
2. 基于统计的方法
3. 基于深度学习的方法

最早大家通过总结规律来判断自然语言的意图，常见的方法有：CFG、JSGF等。

后来出现了基于统计学的 NLU 方式，常见的方法有：[SVM](https://easyai.tech/ai-definition/svm/)、ME等。

随着深度学习的爆发，[CNN](https://easyai.tech/ai-definition/cnn/)、[RNN](https://easyai.tech/ai-definition/rnn/)、[LSTM](https://easyai.tech/ai-definition/lstm/) 都成为了最新的”统治者”。

到了2019年，[BERT](https://easyai.tech/ai-definition/bert/) 和 GPT-2 的表现震惊了业界，他们都是用了 [Transformer](https://easyai.tech/ai-definition/transformer/)，下面将重点介绍 Transformer，因为他是目前「最先进」的方法。



**Transformer 和 CNN / RNN 的比较**

Transformer 的原理比较复杂，这里就不详细说明了，感兴趣的朋友可以查看下面的文章，讲的很详细：

《[BERT大火却不懂Transformer？读这一篇就够了](https://zhuanlan.zhihu.com/p/54356280)》

下面将摘取一部分《[why Self-Attention？A Targeted Evaluation of Neural Machine Translation Architectures](https://arxiv.org/abs/1808.08946)》里的数据，直观的让大家看出来3者的比较。

**语义特征提取能力**

![语义特征抽取能力：Transformer>>原生CNN=原生RNN](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-04-26-tezhengchouqu-2.png)

从语义特征提取能力来说，目前实验支持如下结论：Transformer在这方面的能力非常显著地超过RNN和CNN（在考察语义类能力的任务WSD中，Transformer超过RNN和CNN大约4-8个绝对百分点），RNN和CNN两者能力差不太多。

**长距离特征捕获能力**

![长距离特征抽取能力：Transformer>原生RNN>原生CNN](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-04-26-changjuli.png)

原生CNN特征抽取器在这方面极为显著地弱于RNN和Transformer，Transformer微弱优于RNN模型(尤其在主语谓语距离小于13时)，能力由强到弱排序为Transformer>RNN>>CNN; 但在比较远的距离上（主语谓语距离大于13），RNN微弱优于Transformer，所以综合看，可以认为Transformer和RNN在这方面能力差不太多，而CNN则显著弱于前两者。

**任务综合特征抽取能力**

![任务综合特征抽取能力：Transformer>>原生CNN=原生RNN](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-04-26-zonghe.png)

Transformer综合能力要明显强于RNN和CNN（你要知道，技术发展到现在阶段，BLEU绝对值提升1个点是很难的事情），而RNN和CNN看上去表现基本相当，貌似CNN表现略好一些。

**并行计算能力及运算效率**

![计算效率：Transformer>CNN>RNN](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-04-26-jisuanxiaolv.png)

Transformer Base最快，CNN次之，再次Transformer Big，最慢的是RNN。RNN比前两者慢了3倍到几十倍之间。

关于 Transformer ，推荐几篇优秀的文章给大家，让大家有一个更综合的了解：

《[放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较](https://zhuanlan.zhihu.com/p/54743941)》

《[从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史](https://zhuanlan.zhihu.com/p/49271699)》

《[效果惊人的GPT 2.0模型：它告诉了我们什么](https://zhuanlan.zhihu.com/p/56865533)》

 

## 百度百科-维基百科

百度百科版本

自然语言处理(NLP , Natural Language Processing)是使用自然语言同计算机进行通讯的技术, 因为处理自然语言的关键是要让计算机“理解”自然语言,所以自然语言处理又叫做自然语言理解(NLU ,Natural Language Understanding), 也称为计算语言学(Computational Ling uistics)。一方面它是语言信息处理的一个分支 , 另一方面它是人工智能(AI , Artificial Intelligence)的核心课题之一 。

[查看详情](https://baike.baidu.com/item/自然语言理解)

维基百科版本

自然语言理解（NLU）或自然语言解释（NLI）是的子主题自然语言处理在人工智能与机器涉及阅读理解。自然语言理解被认为是人工智能难题。

由于其应用于自动推理，机器翻译，问答，新闻采集，文本分类，语音激活，存档和大规模内容分析，因此该领域具有相当大的商业利益。。 NLU是使用NLP算法（识别词性等）后的文本的后处理，其利用来自识别设备的上下文（自动语音识别）[[ASR](https://easyai.tech/ai-definition/asr/)]，视觉识别，最后一次会话，来自ASR的误识别词，个性化配置文件，麦克风接近等），以其所有形式，辨别碎片和连续句子的含义以通常从语音命令执行意图。NLU具有围绕特定产品垂直的本体，用于计算意图的概率。NLU具有已定义的已知意图列表，其从指定的上下文信息识别源导出消息有效载荷。NLU将提供多个消息输出以将服务（软件）或资源（硬件）与单个派生的意图分开（对具有视觉句子（显示或说出）的语音命令发起者的响应和转换的语音命令消息将消耗太多不同的输出消息用于M2M通信和行动）。

[查看详情](https://en.wikipedia.org/wiki/Natural-language_understanding)






